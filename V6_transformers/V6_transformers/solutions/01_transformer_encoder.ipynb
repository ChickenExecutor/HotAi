{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will explore the Transformer architecture which is the fundamental building block of today's Large Language Models. A focus will be set on the transformer encoder including the self-attention layer. We will implement a sentiment classification model which predicts the binary sentiment of given movie reviews: positive or negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.583293Z",
     "start_time": "2025-11-28T13:27:03.332736Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start of by loading the movie reviews as well as the corresponding sentiment labels. The label ```y=0``` corresponds to negative sentiment, ```y=1``` corresponds to positive sentiment.\n",
    "\n",
    "Investigate the printed samples to familiarize yourself with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.624460Z",
     "start_time": "2025-11-28T13:27:08.585338Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/movie_reviews.pkl\", \"rb\") as fp:  \n",
    "    texts = pickle.load(fp)\n",
    "with open(\"data/movie_labels.pkl\", \"rb\") as fp:\n",
    "    labels = pickle.load(fp)\n",
    "\n",
    "for text, label in zip(texts[:5], labels):\n",
    "    print(\"Review:\", text, \"Sentiment:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenization\n",
    "In the first processing step we want to tokenize the input sequences. We choose to use simple tokenization and just treat each individual word (seperated by a blank space) as a token. \n",
    "Implement the function ```tokenize_text``` which receives a list of movie reviews. \n",
    "Each review of type `str` is transformed into a list containing the seperate tokens of the sequence (i.e. a list with elements of type `str`). \n",
    "\n",
    "Further, add the classification token ```<cls>``` to the beginning of each token list.\n",
    "This token will later be used as an indicator that a classification based on the subsequent tokens is queried and marks the position where the corresponding output (class prediction) will be computed (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.629338Z",
     "start_time": "2025-11-28T13:27:08.625468Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_text(texts: List[str]) -> List[List[str]]:\n",
    "    tokenized_texts = []\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    for text in texts:\n",
    "        tokenized_text = text.split()\n",
    "        tokenized_text.insert(0, \"<cls>\")\n",
    "        tokenized_texts.append(tokenized_text)\n",
    "    return tokenized_texts\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.638510Z",
     "start_time": "2025-11-28T13:27:08.630756Z"
    }
   },
   "outputs": [],
   "source": [
    "texts_tokenized = tokenize_text(texts)\n",
    "assert len(texts_tokenized) == len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a dictionary to encode the tokens to numeric values, which can be processed by the transformer model. \n",
    "To do so, we map each individual token to a unique index, and, at the same time, assemble the inverse mapping for decoding. \n",
    "Implement the function ```create_dictionaries``` which takes the list of tokenized input sequences and creates both, the ```encoding_dict``` as well as the ```decoding_dict``` which will be used to convert tokens to indices and vice versa. \n",
    "The classification token ```<cls>``` is assigned the index ```0```. \n",
    "Also add a padding token (`pad`) and a token for unknown words (```<unk>```) to the dictionaries and assign the highest indices to them.\n",
    "The padding token will be used to fill shorter sequences to identical lengths, which is necessary as the model requires all input sequences to be of identical lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.647701Z",
     "start_time": "2025-11-28T13:27:08.640667Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dictionaries(texts_tokenized):\n",
    "    encoding_dict = {}\n",
    "    decoding_dict = {}\n",
    "    encoding_dict[\"<cls>\"] = 0\n",
    "    decoding_dict[0] = \"<cls>\"\n",
    "    idx = 1\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    for tokenized_text in texts_tokenized:\n",
    "        for token in tokenized_text:\n",
    "            if token not in encoding_dict:\n",
    "                encoding_dict[token] = idx\n",
    "                decoding_dict[idx] = token\n",
    "                idx +=1\n",
    "    encoding_dict[\"<pad>\"] = idx\n",
    "    decoding_dict[idx] = \"<pad>\"\n",
    "    encoding_dict[\"<unk>\"] = idx+1\n",
    "    decoding_dict[idx+1] = \"<unk>\"\n",
    "    ### END SOLUTION\n",
    "    return encoding_dict, decoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.653944Z",
     "start_time": "2025-11-28T13:27:08.648973Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding_dict, decoding_dict = create_dictionaries(texts_tokenized)\n",
    "assert \"film\" == decoding_dict[encoding_dict[\"film\"]]\n",
    "assert \"music\" == decoding_dict[encoding_dict[\"music\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding dictionary can be used to convert the tokenized training text to numerical values, which can be used as input to our language model.\n",
    "\n",
    "Implement the function `encode_token_sequence(tokenized_sequence: List[str], encoding_dict:Dict[str, int], default_token = \"<unk>\")` which encodes a sequence of tokens based on the given dictionary.\n",
    "Whenever the sequence contains a token which is not contained in the encoding dictionary, use the default token instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.661804Z",
     "start_time": "2025-11-28T13:27:08.654953Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_token_sequence(tokenized_sequence: List[str], encoding_dict: Dict[str, int], default_token = \"<unk>\", max_length=8):\n",
    "    # query default token encoding once\n",
    "    default_token_encoded = encoding_dict[default_token]\n",
    "    encoded_sequence = []\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    for i in range(max_length):\n",
    "        if i < len(tokenized_sequence):\n",
    "            token = tokenized_sequence[i]\n",
    "        else:\n",
    "            token = \"<pad>\"\n",
    "        if token in encoding_dict:\n",
    "            encoded_token = encoding_dict[token]\n",
    "        else:\n",
    "            encoded_token = default_token_encoded\n",
    "        encoded_sequence.append(encoded_token)\n",
    "    ### END SOLUTION\n",
    "    return encoded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert a given sequence of indices back to tokenized text, implement the function ```decode_sequence(encoded_sequence: List[int], decoding_dict: Dict[int, str])``` which decodes a sequence of indices based on the given ```decoding_dict```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.667865Z",
     "start_time": "2025-11-28T13:27:08.662820Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(encoded_sequence: List[int], decoding_dict: Dict[int, str]):\n",
    "    ### BEGIN SOLUTION\n",
    "    decoded_sequence = []\n",
    "    for token in encoded_sequence:\n",
    "        decoded_sequence.append(decoding_dict[token])\n",
    "    ### END SOLUTION\n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ```encode_token_sequence``` to convert the tokenized input sequences ```texts_tokenized``` to sequences of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.674880Z",
     "start_time": "2025-11-28T13:27:08.669245Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_texts = []\n",
    "for tokenized_sequence in texts_tokenized:\n",
    "    encoded = encode_token_sequence(tokenized_sequence, encoding_dict)\n",
    "    encoded_texts.append(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-Attention Implementation\n",
    "##### Scaled dot-product attention\n",
    "After having performed the essential data pre-processing we will now implement the self-attention layer, which is the heart of both transformer encoder and transformer decoder. \n",
    "Therefore, we start off by defining the function ```scaled_dot_product_attention``` which receives ```query```, ```key``` and ```value``` tensors and returns the weighted sum of the ```value``` tensors according to the scaled dot-product formulation introduced in the lecture:\n",
    "$$\\text{attn}(Q,K,V)=\\text{softmax} \\bigg( \\dfrac{QK^T}{\\sqrt{d_k}} \\bigg) V$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.681002Z",
     "start_time": "2025-11-28T13:27:08.675902Z"
    }
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query: torch.Tensor, key: torch.Tensor, value: torch.Tensor):\n",
    "    ### BEGIN SOLUTION\n",
    "    scale_factor = 1 / math.sqrt(key.size(-1)) # factor for scaling the dot-product\n",
    "    scores = query @ key.transpose(-2, -1)\n",
    "    scores = scores * scale_factor\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    weighted_values = scores @ value # weighted sum of value tensors\n",
    "    ### END SOLUTION\n",
    "    return weighted_values, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.708119Z",
     "start_time": "2025-11-28T13:27:08.682022Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_length = 4\n",
    "dk = 128 # dimension of key tensors = dimension of query tensors\n",
    "dv = 64 # dimension of value tensors\n",
    "query = torch.randn(sequence_length, dk)\n",
    "key = torch.randn(sequence_length, dk)\n",
    "value = torch.randn(sequence_length, dv)\n",
    "\n",
    "weighted_values, scores = scaled_dot_product_attention(query, key, value)\n",
    "assert weighted_values.size(-1) == dv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SelfAttentionLayer\n",
    "We continue to use the previously defined function ```scaled_dot_product_attention``` to implement a single layer of the Transformer Encoder. We define the class ```TransformerEncoderLayer``` which inherits from ```torch.nn.Module```. In the ```__init__``` method we first initialize the learnable weight matrices ```self.wq```, ```self.wk``` and ```self.wv``` for computing ```key```, ```query``` and ```value``` vectors in the ```forward``` method.\n",
    "\n",
    "Take a moment to reconsider that this projection of keys, queries and values can in fact be done using PyTorch's linear layer (as the computations of a neural network layer without activation function are basically a multiplication of the input vector by the layer's parameter-matrix).\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"data/encoder_layer.png\" \n",
    "        alt=\"Picture\" \n",
    "        style=\"display: block; margin: 0 auto\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.713668Z",
     "start_time": "2025-11-28T13:27:08.709127Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, dmodel: int, dk: int, dv: int):\n",
    "        super().__init__()\n",
    "        # initialize key, query and value weight matrices for self-attention layer\n",
    "        ### START SOLUTION\n",
    "        self.wq = nn.Linear(dmodel, dk)\n",
    "        self.wk = nn.Linear(dmodel, dk)\n",
    "        self.wv = nn.Linear(dmodel, dv)\n",
    "        ### END SOLUTION\n",
    "\n",
    "        # initialize layer norm and feed-forward network\n",
    "        self.layer_norm1 = nn.LayerNorm(dmodel)\n",
    "        self.linear1 = nn.Linear(dmodel, 1024)\n",
    "        self.linear2 = nn.Linear(1024, dmodel)\n",
    "        self.layer_norm2 = nn.LayerNorm(dmodel)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        ### START SOLUTION\n",
    "        # compute self-attention\n",
    "        query = self.wq(x)\n",
    "        key = self.wk(x)\n",
    "        value = self.wv(x)\n",
    "        weighted_values, scores = scaled_dot_product_attention(query, key, value)\n",
    "        \n",
    "        # add and normalize\n",
    "        x = x + weighted_values\n",
    "        x_res = self.layer_norm1(x)\n",
    "\n",
    "        # feed-forward network\n",
    "        x = self.linear1(x_res)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        # add and normalize\n",
    "        x = x + x_res\n",
    "        z = self.layer_norm2(x)\n",
    "        ### END SOLUTION\n",
    "        return z, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the ```TransformerEncoderLayer``` to implement the final model for the sentiment prediction we have to make sure that the model is able to reason about the positions of the individual tokens in the input sequence. In the lecture we introduced the positional encodings which are added to the token embeddings prior to being passed to the first encoder layer. These encodings are usually following fixed patterns (e.g. sine or cosine functions) which are depending on the respective position in the input sequence. By adding them to the token embeddings the model is able to learn about the absolute or relative positions of the individual tokens in the sequence. In this excercise we implement a positional encoding which follows a sine/cosine pattern. \n",
    "We first initialize the empty matrix $P$ (called ```positional_encoding``` in the code below) of size ```(max_seq_length)```. Next, we start filling the matrix from the first row up to the ```max_length``` row:\n",
    "\n",
    "$$P(k, 2i) = \\sin(\\dfrac{k}{n^{2i/d}})$$\n",
    "$$P(k, 2i + 1) = \\cos(\\dfrac{k}{n^{2i/d}})$$\n",
    "\n",
    "$$ d: \\text{encoder model dimension}$$\n",
    "$$ k: \\text{position of a token in the input sequence} $$\n",
    "$$ n: \\text{user defined scaler}  $$\n",
    "$$ i: \\text{mapping to column indices} \\quad (0 \\leq i < d/2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.741089Z",
     "start_time": "2025-11-28T13:27:08.714686Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(14)\n",
    "torch.cuda.manual_seed(14)\n",
    "dmodel = 128\n",
    "dk = 128\n",
    "dv = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.747550Z",
     "start_time": "2025-11-28T13:27:08.742101Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_positional_encoding(max_seq_length: int, d: int, n: int) -> torch.Tensor:\n",
    "    ### BEGIN SOLUTION\n",
    "    positional_encoding = np.zeros((max_seq_length, d))\n",
    "    for k in np.arange(max_length):\n",
    "        for i in np.arange(d // 2):\n",
    "            theta = k / (n ** ((2 * i) / dmodel))\n",
    "            positional_encoding[k, 2 * i] = math.sin(theta)\n",
    "            positional_encoding[k, 2 * i + 1] = math.cos(theta)\n",
    "    ### BEGIN SOLUTION\n",
    "    return torch.tensor(positional_encoding, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# maximum sequence length\n",
    "max_length = 32\n",
    "encodings = generate_positional_encoding(max_length, dmodel, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.967818Z",
     "start_time": "2025-11-28T13:27:08.748569Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(24, 24))\n",
    "axes.imshow(encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ```TransformerEncoderLayer``` and the positional encodings implemented we are now ready to set up the entire model for predicting the sentiment of given movie reviews. In the ```__init__``` method of our ```SentimentPredictionModel``` we initialize two instances ```self.encoder_layer1``` and ```self.encoder_layer2``` of the ```TransformerEncoderLayer```. In the ```forward``` method we first sum the positional encodings to the token embeddings. These embeddings are then passed through both encoder layers. \n",
    "\n",
    "For our goal of sentiment classification, we will train the model's output in position of the classification token ```<cls>``` (which is at the first position in our input sequence) to contain the class prediction for the complete sequence. \n",
    "Through the self-attention layer, the encoding of the ```<cls>``` should be able to attend to all other tokens of the input sequence and can therefore access all the relevant information of the sequence to classify. \n",
    "The final prediction head computes the class logits for both negative and positive sentiment based on that model output for the classification indicator `<cls>`.\n",
    "These logits are returned for loss computation.\n",
    "\n",
    "(The model output for all other positions in the sequence are not relevant in this case.\n",
    "During training, no loss is computed for these outputs and, thus, they can not be expected to contain meaningful information.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:08.973542Z",
     "start_time": "2025-11-28T13:27:08.969024Z"
    }
   },
   "outputs": [],
   "source": [
    "class SentimentPredictionModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int, dmodel: int, dk: int, dv: int, positional_encodings: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.positional_encodings = positional_encodings\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size, dmodel)\n",
    "        ### BEGIN SOLUTION\n",
    "        self.encoder_layer1 = TransformerEncoderLayer(dmodel, dk, dv)\n",
    "        self.encoder_layer2 = TransformerEncoderLayer(dmodel, dk, dv)\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        self.prediction_head1 = nn.Linear(dmodel, 16)\n",
    "        self.prediction_head2 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer_scores = []\n",
    "        ### BEGIN SOLUTION\n",
    "        x_emb = self.embeddings(x).view((x.shape[0], -1))\n",
    "        positional_encodings = self.positional_encodings[:x_emb.size(0)]\n",
    "\n",
    "        x = x_emb + positional_encodings\n",
    "        z, scores = self.encoder_layer1(x)\n",
    "        layer_scores.append(scores)\n",
    "        z, scores = self.encoder_layer2(z)\n",
    "        layer_scores.append(scores)\n",
    "        ### END SOLUTION\n",
    "\n",
    "        z_class = z[0]\n",
    "        pred = F.relu(self.prediction_head1(z_class))\n",
    "        class_logits = self.prediction_head2(pred)\n",
    "        return class_logits, layer_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment Classification\n",
    "\n",
    "In the final step we can now train our sentiment classification model on the movie review dataset. Therefore we split the entire dataset into a training and a validation dataset and instantiate DataLoader instances for both: ```train_loader``` and ```val_loader```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:11.026332Z",
     "start_time": "2025-11-28T13:27:08.974549Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SentimentPredictionModel(len(encoding_dict), dmodel, dk, dv, encodings)\n",
    "lr = 1e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cpu'\n",
    "\n",
    "train_idx = int(len(encoded_texts) * 0.5)\n",
    "encoded_texts_train = torch.tensor(encoded_texts[:train_idx])\n",
    "labels_train = labels[:train_idx]\n",
    "encoded_texts_val = torch.tensor(encoded_texts[train_idx:])\n",
    "labels_val = labels[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:11.031696Z",
     "start_time": "2025-11-28T13:27:11.027346Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(encoded_texts_train, labels_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(encoded_texts_val, labels_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Inside the training loop, please implement the core training functionalities:\n",
    " * extract the movie review texts and the corresponding sentiment labels\n",
    " * pass the batch of review texts through the model to obtain the prediction ```out``` and the attention scores ```scores```\n",
    " * use the prediction and the groundtruth label to compute the ```loss``` value\n",
    " * execute one step of gradient descent (remember to call `zero_grad()` before executing the loss' `backward()` pass and computing the weight updates via `step()`)\n",
    " * add the loss computed after the forward pass of the current batch to ```episode_loss_train```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:39.142448Z",
     "start_time": "2025-11-28T13:27:11.032702Z"
    }
   },
   "outputs": [],
   "source": [
    "n_episodes = 100\n",
    "episode_losses_train = []\n",
    "episode_losses_val = []\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    episode_loss_train = 0\n",
    "    episode_loss_val = 0\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        sample_x, sample_y = sample\n",
    "        ### START SOLUTION\n",
    "        out, scores = model(sample_x.squeeze())\n",
    "        loss = criterion(out, sample_y[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        episode_loss_train += loss.item()\n",
    "        #### END SOLUTION\n",
    "        \n",
    "    model.eval()\n",
    "    for batch_idx, sample in enumerate(val_loader):\n",
    "        sample_x, sample_y = sample\n",
    "        out, scores = model(sample_x.squeeze())\n",
    "        loss = criterion(out, sample_y[0])\n",
    "        episode_loss_val += loss.item()\n",
    "    episode_losses_train.append(episode_loss_train / len(encoded_texts_train))\n",
    "    episode_losses_val.append(episode_loss_val / len(encoded_texts_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Loss Visualization\n",
    "\n",
    "Looking at the training and validation loss, what behaviour can you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:39.213307Z",
     "start_time": "2025-11-28T13:27:39.143731Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1)\n",
    "axes.plot(episode_losses_train)\n",
    "axes.plot(episode_losses_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Score Visualization\n",
    "\n",
    "The following code cells produce a visualization of the scores computed in the self-attention mechanism for a single training sample.\n",
    "\n",
    "If you focus on the first row in the matrix-shaped color based visualization (the row for the `<cls>`-token), you can identify the sequence's tokens which the classifier attends to most.\n",
    "\n",
    "Visualize the attention scores for different data samples, investigate how they vary and which words seem to be important for the model's classification decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:39.221481Z",
     "start_time": "2025-11-28T13:27:39.214313Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_text = list(encoded_texts_train[13].tolist())\n",
    "print(encoded_text)\n",
    "decoded_text = decode_sequence(encoded_text, decoding_dict)\n",
    "print(decoded_text)\n",
    "out, scores = model(torch.tensor(encoded_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:27:39.335600Z",
     "start_time": "2025-11-28T13:27:39.222486Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1)\n",
    "im = axes.imshow(scores[0].detach())\n",
    "plt.colorbar(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
