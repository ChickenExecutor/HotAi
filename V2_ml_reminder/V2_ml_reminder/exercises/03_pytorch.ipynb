{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with PyTorch - Exercises\n",
    "\n",
    "PyTorch is one of the most-used pthon library for deep learning, in a broad variety of applications.\n",
    "\n",
    "Even though it is not designed for simple regression problems, it can be used to solve such tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "The following lines import the packages required in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Creation\n",
    "\n",
    "We explore linear regression in PyTorch using the same problem description as previously in exercise \"01_linear_regression\".\n",
    "\n",
    "You are welcome to copy the code to create training data arrays ``X_train`` and ``y_train``.\n",
    "\n",
    "(Once again, use parameter values ``w0=2.0``, ``w1=1.5`` and add Gaussian noise of standard deviation 0.15 to the y-values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input samples\n",
    "n_samples = 15\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "# x_1 values in the range (0, 10)\n",
    "# constants x_0 of the same shape as x_1\n",
    "# input data X\n",
    "# true model parameters\n",
    "# output data y \n",
    "\n",
    "x1_train  = np.random.uniform(0, 1, size=(n_samples, 1))\n",
    "x0_train = np.ones(shape=(n_samples, 1))\n",
    "x_train = np.concatenate([x0_train, x1_train], axis=1)\n",
    "\n",
    "w_true = np.array([2.0,1.5])\n",
    "w_true  = w_true.reshape(2,1)\n",
    "\n",
    "y_train = np.matmul(x_train, w_true)\n",
    "\n",
    "y_train += np.random.normal(0,0.15, size  = y_train.shape)\n",
    "\n",
    "\n",
    "### END OF SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the training data (x- and y-values) into a PyTorch Tensors, which is necessary for subsequent use with the PyTorch library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_x = torch.Tensor(x1_train) \n",
    "training_data_y = torch.Tensor(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, the linear regression problem will not be solved using the closed form solution, but an iterative loss minimization approach.\n",
    "\n",
    "Even though we have not covered the theory yet (we will do so next week),\n",
    "a simple artificial neuron (without non-linear activation function) is methodically identical to basic linear regression.\n",
    "A simple neural layer is implemented in PyTorch's class ``nn.Linear()``, and a single neuron model can be initialized by ``nn.Linear(1, 1)``.\n",
    "\n",
    "First, implement the class ```LinearRegressor``` which inherits from ```nn.Module```. In the ```__init__``` function add a linear layer using ```nn.Linear()```. This layer takes a single input value x and outputs the corresponding prediction y_pred. Also implement the ```forward(self, x)``` for the forward pass of the regressor. For details see the documentation at https://pytorch.org/docs/stable/generated/torch.nn.Module.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR SOLUTION HERE\n",
    "class LinearRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "    \n",
    "### END OF SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the (parameter-free) constructor of our model class ``LinearRegressor``, the model can be initialized.\n",
    "\n",
    "In this step, model parameters are initialized randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement a method to plot the training progress during training using matplotlib and the Jupyter Matplotlib inline feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_viz(fig, axes, losses, training_data_x, training_data_y):\n",
    "    x_viz = torch.linspace(0, 10, 100).reshape(-1, 1)\n",
    "    y_viz = regressor(x_viz).detach().numpy()\n",
    "    axes[0].cla()\n",
    "    axes[1].cla()\n",
    "    axes[0].set_xlim([0, 10])\n",
    "    axes[0].set_ylim([0, 20])\n",
    "    axes[1].set_xlim([0, 100])\n",
    "    axes[1].set_ylim([0, 100])\n",
    "    axes[1].plot(losses, label='mean squared error')\n",
    "    axes[0].scatter(training_data_x.detach().numpy(), training_data_y.detach().numpy(), label='training samples')\n",
    "    axes[0].plot(x_viz, y_viz, color='red', label='current model')\n",
    "    axes[0].legend()\n",
    "    axes[1].legend()\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block performs the training with PyTorch.\n",
    "\n",
    "Using already implemented loss functions and gradients, the computed loss for model prediction's and training data is iteratively minimized, thereby finding the optimal training parameters.\n",
    "\n",
    "During training, the training progress is illustrated below.\n",
    "\n",
    "You can try different learning rates and also vary the training data to see how training process and convergence speed vary.\n",
    "\n",
    "*Attention:* Model parameters are stored in the LinearRegressor instance. If you change the setup, re-initialize the model to reset the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegressor' object has no attribute 'linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m optimizer.zero_grad()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# predict target values for the input training data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m y_pred = \u001b[43mregressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# compute loss (compare predicted targets to annotations)\u001b[39;00m\n\u001b[32m     21\u001b[39m loss = loss_fn(y_pred, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\HotAI\\HotAi\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\HotAI\\HotAi\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mLinearRegressor.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m(x)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\HotAI\\HotAi\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'LinearRegressor' object has no attribute 'linear'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "n_episodes = 100\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "learning_rate = 5e-4\n",
    "optimizer = torch.optim.SGD(regressor.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "for i in range(n_episodes):\n",
    "\n",
    "    x_train = training_data_x.reshape(-1, 1)\n",
    "    y_train = training_data_y.reshape(-1, 1)\n",
    "    \n",
    "    # Training loop\n",
    "    # Set gradients to zero (pytorch stores gradients for each parameter during backwards pass, they need to be explicitly set to zero before each training iteration)\n",
    "    optimizer.zero_grad()\n",
    "    # predict target values for the input training data\n",
    "    y_pred = regressor(x_train)\n",
    "    # compute loss (compare predicted targets to annotations)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    # perform backward pass -> compute gradients for each parameter)\n",
    "    loss.backward()\n",
    "    # perform optimizer step, i.e. adjust parameters values according to gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # store the loss of the performed training iteration (for plotting and tracking of training progress)\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    update_viz(fig, axes, losses, training_data_x, training_data_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
