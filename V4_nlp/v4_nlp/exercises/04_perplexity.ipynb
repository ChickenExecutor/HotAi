{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "id": "0", "metadata": {"collapsed": false}, "source": "# Language Model Metrics: Perplexity - Exercises"}, {"cell_type": "markdown", "id": "1", "metadata": {"collapsed": false}, "source": "### Definition of Perplexity\n\nThe commonly used metric to evaluate language models is called *Perplexity*.\n\nAssume data samples, i.e. sentences $x^{(i)}, i = 1, ..., N$ with every sentence consisting of a sequence of tokens (words) $x^{(i)} = x^{(i)}_1 x^{(i)}_2 ... x^{(i)}_{k_i}$, are given.\nThe perplexity of a model on the given data is defined as \n\n$ PPL(\\theta) = \\exp \\left( - \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{k=1}^{k_i} \\log {P_{\\theta}(x^{(i)}_{k}|x^{(i)}_1...x^{(i)}_{k-1})} \\right) $\n\nwhere $\\theta$ are the model's parameters and $P_{\\theta}(x^{(i)}_{k}|x^{(i)}_1...x^{(i)}_{k-1})$ is the probability that the model outputs $x^{(i)}_{k}$ given the previous sequence of tokens."}, {"cell_type": "markdown", "id": "2", "metadata": {"collapsed": false}, "source": "The following implementation of the Softmax function will be required to convert the model scores to probabilities.\n\nIt is already known from a previous tutorial."}, {"cell_type": "code", "execution_count": null, "id": "3", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:30:21.415647Z", "start_time": "2025-11-17T13:30:21.338103Z"}, "collapsed": false}, "outputs": [], "source": "import math\n\nimport numpy as np\n\ndef softmax(values):\n    exp_values = np.exp(values)\n    exp_values_sum = np.sum(exp_values)\n    return exp_values/exp_values_sum"}, {"cell_type": "markdown", "id": "4", "metadata": {"collapsed": false}, "source": "### Exercise: Implementation of Perplexity\n\nImplement the computation of the perplexity function as defined above.\n\nThe function parameters are the scores output by the model (`token_scores`) of dimension (`n_samples`, `n_classes`), and the true class indices (`true_token_index`) which is an array of dimension (`n_samples`).\n\nIn case the model scores do not resemble a probability distribution, the softmax function is applied to the scores for each prediction first. \nThe last function parameter `apply_softmax` indicates whether a the softmax function should be applied."}, {"cell_type": "code", "execution_count": null, "id": "5", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:30:21.420416Z", "start_time": "2025-11-17T13:30:21.417020Z"}, "collapsed": true}, "outputs": [], "source": "def perplexity(token_scores, true_token_index, apply_softmax=True):\n    log_prob_sum = 0\n    if apply_softmax:\n        token_probabilities = [softmax(scores) for scores in token_scores]\n    else:\n        token_probabilities = token_scores\n    \n    ### YOUR SOLUTION HERE\n    ### END OF SOLUTION\n    \n    return perplexity"}, {"cell_type": "code", "execution_count": null, "id": "6", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:30:21.428583Z", "start_time": "2025-11-17T13:30:21.421421Z"}, "collapsed": false}, "outputs": [], "source": "### test implementation\nassert np.isclose(perplexity([[1e8, -1e8]], [0], apply_softmax=False), 0)\nassert np.isclose(perplexity([[1,0,0,0]], [0], apply_softmax=False), 1)\nassert np.isclose(perplexity([[0.5, 0.5]], [0], apply_softmax=False), 2)\nassert np.isclose(perplexity([[1, 2, 7], [2, -1, 0], [0, 1, 0], [1, 0.2, 0.2]], [2, 0, 1, 0], apply_softmax=True), 1.409032255704535)"}, {"cell_type": "markdown", "id": "7", "metadata": {"collapsed": false}, "source": "### Exercise: Perplexity function using Cross Entropy Loss\n\nYou might have noticed that the perplexity function has a high similarity to the cross entropy loss which we have already seen in previous lectures and tutorials.\nRemember:\n\n$ \\text{CrossEntropyLoss} = - \\sum_{i=1}^{N} \\sum_{k=1}^{k_i} \\log {P_{\\theta}(x^{(i)}_{k}|x^{(i)}_1...x^{(i)}_{k-1})} $\n\nThe cross entropy Loss is already implemented in PyTorch's class `torch.nn.CrossEntropyLoss` (compare previous tutorial).\nIf the cross entropy loss is initialized without any parameters, the returned results will already be normed by the number of samples in the data (this could be avoided by setting the named parameter `reduction='sum'` or `reduction='none'` but is not necessary in this case). \n\nUse this existing implementation to compute the perplexity score based on the cross entropy loss.\n\nThe parameters of the function `perplexity_ce_based` are identical to those of the previously implemented function `perplexity`.\nThe first step in the implementation is to convert the given arrays to tensors, so they can be input to PyTorch's cross entropy computation."}, {"cell_type": "code", "execution_count": null, "id": "8", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:30:22.471295Z", "start_time": "2025-11-17T13:30:21.429592Z"}, "collapsed": false}, "outputs": [], "source": "import torch\n\ndef perplexity_ce_based(token_scores, true_token_index):\n    token_scores_tensor = torch.tensor(token_scores)\n    true_token_index_tensor = torch.tensor(true_token_index).long()\n    ### YOUR SOLUTION HERE\n    ### END OF SOLUTION\n    return perplexity"}, {"cell_type": "markdown", "id": "9", "metadata": {"collapsed": false}, "source": "The following code cell initializes randomized numpy arrays which can be used to test your function implementations. \n\nIf implemented correctly, the difference between the functions' return values should be extremely close to zero."}, {"cell_type": "code", "execution_count": null, "id": "10", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:32:28.110353Z", "start_time": "2025-11-17T13:32:28.103760Z"}, "collapsed": false}, "outputs": [], "source": "### randomized test case\nscores = np.double(np.random.random((12, 8)))\ntrue_classes = np.random.randint(0, 8, 12)\n\nppl_1 = perplexity(scores, true_classes, apply_softmax=True)\nppl_2 = perplexity_ce_based(scores, true_classes)\n\nppl_diff = np.abs(ppl_1 - ppl_2)\nprint(ppl_diff)"}, {"cell_type": "markdown", "id": "11", "metadata": {"collapsed": false}, "source": "### Application of Perplexity\n\nNext, we will apply the computation of a perplexity score to the n_gram model from the previous exercise. \n\nThe following code cell once again defines a small sample corpus and computes the corresponding ngram-frequencies for n=3."}, {"cell_type": "code", "execution_count": null, "id": "12", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:32:36.770518Z", "start_time": "2025-11-17T13:32:36.765679Z"}, "collapsed": false}, "outputs": [], "source": "from sklearn.feature_extraction.text import CountVectorizer\n\nn = 3\n\ncorpus = [\n    \"sos the fox is brown and quick eos\",\n    \"sos the dog is brown and lazy eos\",\n    \"sos the dog is very lazy eos\",\n    \"sos the fox is very quick eos\"\n]\n\nvectorizer = CountVectorizer(ngram_range=(n, n))  # Generate n-grams of size n\nX = vectorizer.fit_transform(corpus)\nn_grams = vectorizer.get_feature_names_out()\n\nn_gram_freq = {}\nfor ngram, count in zip(n_grams, X.toarray().sum(axis=0)):\n    n_gram_freq[ngram] = count"}, {"cell_type": "markdown", "id": "13", "metadata": {"collapsed": false}, "source": "We use another CountVectorizer to get a list of all single tokens in the corpus vocabulary.\nThis will be needed to compute the probabilities for each token based on the n-gram frequencies subsequently."}, {"cell_type": "code", "execution_count": null, "id": "14", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:32:40.840422Z", "start_time": "2025-11-17T13:32:40.836172Z"}, "collapsed": false}, "outputs": [], "source": "vectorizer_single_tokens = CountVectorizer(ngram_range=(1, 1))\nvectorizer_single_tokens.fit_transform(corpus)\ntokens = vectorizer_single_tokens.get_feature_names_out()"}, {"cell_type": "markdown", "id": "15", "metadata": {"collapsed": false}, "source": "We will use a single test sentence to compute the n-gram model's perplexity score."}, {"cell_type": "code", "execution_count": null, "id": "16", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:32:41.795184Z", "start_time": "2025-11-17T13:32:41.790690Z"}, "collapsed": false}, "outputs": [], "source": "eval_text = [\"sos the fox is very quick eos\"]"}, {"cell_type": "markdown", "id": "17", "metadata": {"collapsed": false}, "source": "Next, we will implement a function which computes the probabilities for each word in the vocabulary to be the next token (even if the corresponding n-gram does not occur in the corpus).\nThese probabilities are required to compute a model perplexity score."}, {"cell_type": "code", "execution_count": null, "id": "18", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:32:43.443584Z", "start_time": "2025-11-17T13:32:43.439004Z"}, "collapsed": false}, "outputs": [], "source": "def get_next_token_probabilities(ngram_prefix, n_gram_freq, tokens):\n    candidates = {ngram: count for ngram, count in n_gram_freq.items() if ngram.startswith(ngram_prefix)}\n    freq_sum = sum(candidates.values())\n    # probs will be the list containing the probabilities for each token in tokens to be predicted by the n-gram language model \n    probs = []\n    ### YOUR SOLUTION HERE\n    # for each token in tokens, compute the corresponding probability and append it to the list 'probs'\n    ### END OF SOLUTION\n    return probs"}, {"cell_type": "markdown", "id": "19", "metadata": {"collapsed": false}, "source": "Now, we will iterate over all n-grams in the evaluation text and compute the probabilties for each token to be output as final token of the n-gram.\nThese probabilities are assembled in the array `eval_ngram_probabilities`.\nAt the same time, the corresponding indices of the true next token are stored in the array `eval_true_tokens`. "}, {"cell_type": "code", "execution_count": null, "id": "20", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:32:48.931725Z", "start_time": "2025-11-17T13:32:48.926719Z"}, "collapsed": false}, "outputs": [], "source": "eval_ngram_probabilities = []\neval_true_tokens = []\n\n### YOUR SOLUTION HERE\n### END OF SOLUTION"}, {"cell_type": "markdown", "id": "21", "metadata": {"collapsed": false}, "source": "Based on the previously computed token probabilities, we can compute a perplexity score.\n\nNote, that the softmax function should not be applied within the perplexity score computation as our model already outputs a probability distribution.\n(Multiple subsequent applications of the softmax function leads to levelling of the different scores.)"}, {"cell_type": "code", "execution_count": null, "id": "22", "metadata": {"ExecuteTime": {"end_time": "2025-11-17T13:32:53.814776Z", "start_time": "2025-11-17T13:32:53.810652Z"}, "collapsed": false}, "outputs": [], "source": "ppl = perplexity(eval_ngram_probabilities, eval_true_tokens, apply_softmax=False)\nprint(ppl)"}]}